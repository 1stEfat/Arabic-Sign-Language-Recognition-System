{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8597c1fc",
   "metadata": {},
   "source": [
    " ============================================================================\n",
    " REAL-TIME HAND SIGN RECOGNITION WITH WEBCAM\n",
    " Jupyter Notebook - Live Prediction from Camera\n",
    " ============================================================================\n",
    "\n",
    " This notebook loads your trained model and performs real-time hand sign\n",
    " recognition using your laptop's webcam.\n",
    "\n",
    " Requirements:\n",
    "  - Trained model file (best_model.pth or best_model.h5)\n",
    "  - Webcam/camera access\n",
    "  - Same preprocessing as training\n",
    "\n",
    " ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0d0222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using PyTorch 2.7.1+cu118\n",
      "‚úÖ CUDA Available: True\n",
      "================================================================================\n",
      "üìπ REAL-TIME HAND SIGN RECOGNITION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Choose your framework: 'pytorch' or 'keras' (MUST match training)\n",
    "FRAMEWORK = 'pytorch'  # Change to 'keras' if you trained with Keras\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torchvision.transforms as transforms\n",
    "    print(f\"‚úÖ Using PyTorch {torch.__version__}\")\n",
    "    print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    print(f\"‚úÖ Using TensorFlow {tf.__version__}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìπ REAL-TIME HAND SIGN RECOGNITION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec89e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   Model Path: best_model.pth\n",
      "   Image Size: 224x224\n",
      "   Number of Classes: 28\n",
      "   Device: cuda\n",
      "   Camera ID: 0\n",
      "   Confidence Threshold: 0.5\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    # Model parameters (MUST match training configuration)\n",
    "    IMG_SIZE = 224\n",
    "    NUM_CLASSES = 28  # Change to match your number of classes\n",
    "    \n",
    "    # Model file path\n",
    "    MODEL_PATH = 'best_model.pth'  # or 'best_model.h5' for Keras\n",
    "    \n",
    "    # Camera settings\n",
    "    CAMERA_ID = 0  # Usually 0 for built-in webcam, try 1 if not working\n",
    "    CAMERA_WIDTH = 640\n",
    "    CAMERA_HEIGHT = 480\n",
    "    \n",
    "    # Display settings\n",
    "    CONFIDENCE_THRESHOLD = 0.5  # Minimum confidence to show prediction\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = 'cuda' if FRAMEWORK == 'pytorch' and torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Class names - Using numeric labels (0-27)\n",
    "    CLASS_NAMES = [f'Class {i}' for i in range(NUM_CLASSES)]\n",
    "    \n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Model Path: {config.MODEL_PATH}\")\n",
    "print(f\"   Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
    "print(f\"   Number of Classes: {config.NUM_CLASSES}\")\n",
    "print(f\"   Device: {config.DEVICE}\")\n",
    "print(f\"   Camera ID: {config.CAMERA_ID}\")\n",
    "print(f\"   Confidence Threshold: {config.CONFIDENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2efba0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 3: MODEL ARCHITECTURE (must match training)\n",
    "# ============================================================================\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    \n",
    "    class HandSignCNN(nn.Module):\n",
    "        \"\"\"Custom CNN Architecture - MUST MATCH TRAINING\"\"\"\n",
    "        \n",
    "        def __init__(self, num_classes=10):\n",
    "            super(HandSignCNN, self).__init__()\n",
    "            \n",
    "            # Convolutional Block 1\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout2d(0.25)\n",
    "            )\n",
    "            \n",
    "            # Convolutional Block 2\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout2d(0.25)\n",
    "            )\n",
    "            \n",
    "            # Convolutional Block 3\n",
    "            self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout2d(0.25)\n",
    "            )\n",
    "            \n",
    "            # Convolutional Block 4\n",
    "            self.conv4 = nn.Sequential(\n",
    "                nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout2d(0.25)\n",
    "            )\n",
    "            \n",
    "            # Global Average Pooling\n",
    "            self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "            # Fully Connected Layers\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(256, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, num_classes)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv4(x)\n",
    "            x = self.global_avg_pool(x)\n",
    "            x = self.fc(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eaff74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Loading trained model...\n",
      "   ‚úÖ PyTorch model loaded successfully!\n",
      "   üìä Model ready for inference on cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 4: LOAD TRAINED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÑ Loading trained model...\")\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    # Create model\n",
    "    model = HandSignCNN(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
    "    \n",
    "    # Load weights\n",
    "    if not os.path.exists(config.MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found: {config.MODEL_PATH}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(config.MODEL_PATH, map_location=config.DEVICE))\n",
    "    model.eval()\n",
    "    \n",
    "    # Define preprocessing transform (MUST match training)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    print(\"   ‚úÖ PyTorch model loaded successfully!\")\n",
    "    \n",
    "else:  # Keras\n",
    "    if not os.path.exists(config.MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found: {config.MODEL_PATH}\")\n",
    "    \n",
    "    model = keras.models.load_model(config.MODEL_PATH)\n",
    "    print(\"   ‚úÖ Keras model loaded successfully!\")\n",
    "\n",
    "print(f\"   üìä Model ready for inference on {config.DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "790700e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 5: PREDICTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def predict_frame(frame, model, transform=None):\n",
    "    \"\"\"\n",
    "    Predict hand sign from a camera frame\n",
    "    \n",
    "    Args:\n",
    "        frame: OpenCV frame (BGR format)\n",
    "        model: Trained model\n",
    "        transform: Preprocessing transform (for PyTorch)\n",
    "    \n",
    "    Returns:\n",
    "        predicted_class: Predicted class index\n",
    "        confidence: Prediction confidence\n",
    "        all_probs: All class probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if FRAMEWORK == 'pytorch':\n",
    "        # Preprocess\n",
    "        input_tensor = transform(rgb_frame).unsqueeze(0).to(config.DEVICE)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            confidence, predicted = torch.max(probs, 1)\n",
    "            \n",
    "        predicted_class = predicted.item()\n",
    "        confidence = confidence.item()\n",
    "        all_probs = probs.cpu().numpy()[0]\n",
    "        \n",
    "    else:  # Keras\n",
    "        # Preprocess\n",
    "        img = cv2.resize(rgb_frame, (config.IMG_SIZE, config.IMG_SIZE))\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Predict\n",
    "        probs = model.predict(img, verbose=0)[0]\n",
    "        predicted_class = np.argmax(probs)\n",
    "        confidence = probs[predicted_class]\n",
    "        all_probs = probs\n",
    "    \n",
    "    return predicted_class, confidence, all_probs\n",
    "\n",
    "\n",
    "def draw_prediction_on_frame(frame, predicted_class, confidence, all_probs, top_k=3):\n",
    "    \"\"\"Draw prediction results on the frame\"\"\"\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Create overlay for better readability\n",
    "    overlay = frame.copy()\n",
    "    \n",
    "    # Draw semi-transparent background for text\n",
    "    cv2.rectangle(overlay, (10, 10), (w - 10, 200), (0, 0, 0), -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)\n",
    "    \n",
    "    # Main prediction\n",
    "    class_name = config.CLASS_NAMES[predicted_class]\n",
    "    \n",
    "    # Color based on confidence\n",
    "    if confidence >= 0.8:\n",
    "        color = (0, 255, 0)  # Green\n",
    "    elif confidence >= 0.5:\n",
    "        color = (0, 255, 255)  # Yellow\n",
    "    else:\n",
    "        color = (0, 165, 255)  # Orange\n",
    "    \n",
    "    # Draw main prediction\n",
    "    text = f\"Prediction: {class_name}\"\n",
    "    cv2.putText(frame, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1.2, color, 3, cv2.LINE_AA)\n",
    "    \n",
    "    conf_text = f\"Confidence: {confidence:.2%}\"\n",
    "    cv2.putText(frame, conf_text, (20, 90), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.8, color, 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Draw top-k predictions\n",
    "    top_k_indices = np.argsort(all_probs)[-top_k:][::-1]\n",
    "    \n",
    "    y_offset = 130\n",
    "    cv2.putText(frame, f\"Top {top_k}:\", (20, y_offset), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    for i, idx in enumerate(top_k_indices):\n",
    "        y_offset += 30\n",
    "        text = f\"{i+1}. {config.CLASS_NAMES[idx]}: {all_probs[idx]:.2%}\"\n",
    "        cv2.putText(frame, text, (30, y_offset), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Draw instructions\n",
    "    instructions = \"Press 'q' to quit | 's' to save snapshot\"\n",
    "    cv2.putText(frame, instructions, (20, h - 20), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (200, 200, 200), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Draw FPS\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3d6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6: MAIN CAMERA LOOP\n",
    "# ============================================================================\n",
    "\n",
    "def run_camera_inference():\n",
    "    \"\"\"Main function to run real-time inference from camera\"\"\"\n",
    "    \n",
    "    print(\"\\nüìπ Starting camera...\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"CONTROLS:\")\n",
    "    print(\"  Press 'q' to quit\")\n",
    "    print(\"  Press 's' to save snapshot\")\n",
    "    print(\"  Press 'p' to pause/resume\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Open camera\n",
    "    cap = cv2.VideoCapture(config.CAMERA_ID)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Error: Could not open camera!\")\n",
    "        print(\"   Try changing CAMERA_ID in config (0, 1, 2, etc.)\")\n",
    "        return\n",
    "    \n",
    "    # Set camera properties\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, config.CAMERA_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config.CAMERA_HEIGHT)\n",
    "    \n",
    "    print(\"‚úÖ Camera opened successfully!\")\n",
    "    print(\"\\nüé¨ Press any key in the video window to start...\")\n",
    "    \n",
    "    # For FPS calculation\n",
    "    fps_time = time.time()\n",
    "    fps_counter = 0\n",
    "    fps_display = 0\n",
    "    \n",
    "    paused = False\n",
    "    snapshot_counter = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            if not paused:\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                if not ret:\n",
    "                    print(\"‚ùå Error: Failed to grab frame\")\n",
    "                    break\n",
    "                \n",
    "                # Make prediction\n",
    "                predicted_class, confidence, all_probs = predict_frame(\n",
    "                    frame, model, transform if FRAMEWORK == 'pytorch' else None\n",
    "                )\n",
    "                \n",
    "                # Draw results on frame\n",
    "                frame = draw_prediction_on_frame(frame, predicted_class, \n",
    "                                                confidence, all_probs)\n",
    "                \n",
    "                # Calculate and draw FPS\n",
    "                fps_counter += 1\n",
    "                if time.time() - fps_time > 1:\n",
    "                    fps_display = fps_counter\n",
    "                    fps_counter = 0\n",
    "                    fps_time = time.time()\n",
    "                \n",
    "                cv2.putText(frame, f\"FPS: {fps_display}\", (frame.shape[1] - 120, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display frame\n",
    "            cv2.imshow('Hand Sign Recognition', frame)\n",
    "            \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                print(\"\\nüëã Quitting...\")\n",
    "                break\n",
    "            \n",
    "            elif key == ord('s'):\n",
    "                # Save snapshot\n",
    "                snapshot_counter += 1\n",
    "                filename = f\"snapshot_{snapshot_counter}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"üì∏ Snapshot saved: {filename}\")\n",
    "            \n",
    "            elif key == ord('p'):\n",
    "                # Pause/resume\n",
    "                paused = not paused\n",
    "                status = \"PAUSED\" if paused else \"RESUMED\"\n",
    "                print(f\"‚è∏Ô∏è  {status}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è  Interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n‚úÖ Camera closed\")\n",
    "        print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b831d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Ready to start!\n",
      "\n",
      "Run the cell below to start the camera inference:\n",
      "   run_camera_inference()\n",
      "\n",
      "üìπ Starting camera...\n",
      "================================================================================\n",
      "CONTROLS:\n",
      "  Press 'q' to quit\n",
      "  Press 's' to save snapshot\n",
      "  Press 'p' to pause/resume\n",
      "================================================================================\n",
      "‚úÖ Camera opened successfully!\n",
      "\n",
      "üé¨ Press any key in the video window to start...\n",
      "\n",
      "üëã Quitting...\n",
      "\n",
      "‚úÖ Camera closed\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7: RUN THE APPLICATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüöÄ Ready to start!\")\n",
    "print(\"\\nRun the cell below to start the camera inference:\")\n",
    "print(\"   run_camera_inference()\")\n",
    "\n",
    "# %%\n",
    "# Start the camera application\n",
    "run_camera_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff61449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ SETUP COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìå Quick Start:\n",
      "   1. Make sure your webcam is connected\n",
      "   2. Run: run_camera_inference()\n",
      "   3. Show hand signs to the camera\n",
      "   4. Press 'q' to quit, 's' to save snapshot\n",
      "\n",
      "üìå Test single image:\n",
      "   test_single_image('path/to/image.jpg')\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: SINGLE IMAGE TEST\n",
    "# ============================================================================\n",
    "\n",
    "def test_single_image(image_path):\n",
    "    \"\"\"Test the model on a single image file\"\"\"\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"‚ùå Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"‚ùå Failed to load image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_class, confidence, all_probs = predict_frame(\n",
    "        img, model, transform if FRAMEWORK == 'pytorch' else None\n",
    "    )\n",
    "    \n",
    "    # Draw results\n",
    "    result_img = draw_prediction_on_frame(img.copy(), predicted_class, \n",
    "                                          confidence, all_probs)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Prediction: {config.CLASS_NAMES[predicted_class]} ({confidence:.2%})', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Prediction Results:\")\n",
    "    print(f\"   Class: {config.CLASS_NAMES[predicted_class]}\")\n",
    "    print(f\"   Confidence: {confidence:.2%}\")\n",
    "    print(f\"\\n   Top 5 Predictions:\")\n",
    "    top5 = np.argsort(all_probs)[-5:][::-1]\n",
    "    for i, idx in enumerate(top5):\n",
    "        print(f\"   {i+1}. {config.CLASS_NAMES[idx]}: {all_probs[idx]:.2%}\")\n",
    "\n",
    "# Example usage:\n",
    "# test_single_image('path/to/your/image.jpg')\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ SETUP COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìå Quick Start:\")\n",
    "print(\"   1. Make sure your webcam is connected\")\n",
    "print(\"   2. Run: run_camera_inference()\")\n",
    "print(\"   3. Show hand signs to the camera\")\n",
    "print(\"   4. Press 'q' to quit, 's' to save snapshot\")\n",
    "print(\"\\nüìå Test single image:\")\n",
    "print(\"   test_single_image('path/to/image.jpg')\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
